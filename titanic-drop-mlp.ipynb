{"cells":[{"cell_type":"code","execution_count":355,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T16:59:56.450264Z","iopub.status.busy":"2024-01-23T16:59:56.449495Z","iopub.status.idle":"2024-01-23T16:59:56.455426Z","shell.execute_reply":"2024-01-23T16:59:56.454466Z","shell.execute_reply.started":"2024-01-23T16:59:56.450227Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import pandas as pd\n","import numpy as np\n"]},{"cell_type":"code","execution_count":356,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T16:59:56.463867Z","iopub.status.busy":"2024-01-23T16:59:56.463588Z","iopub.status.idle":"2024-01-23T16:59:56.479774Z","shell.execute_reply":"2024-01-23T16:59:56.478922Z","shell.execute_reply.started":"2024-01-23T16:59:56.463841Z"},"trusted":true},"outputs":[],"source":["# Load the Titanic dataset (replace with your dataset path)\n","train_df = pd.read_csv('/kaggle/input/titanic/train.csv')\n","test_df = pd.read_csv('/kaggle/input/titanic/test.csv')\n","\n"]},{"cell_type":"code","execution_count":357,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T16:59:56.481938Z","iopub.status.busy":"2024-01-23T16:59:56.481342Z","iopub.status.idle":"2024-01-23T16:59:56.504203Z","shell.execute_reply":"2024-01-23T16:59:56.502956Z","shell.execute_reply.started":"2024-01-23T16:59:56.481903Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>886</th>\n","      <td>887</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Montvila, Rev. Juozas</td>\n","      <td>male</td>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>211536</td>\n","      <td>13.0000</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>888</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Graham, Miss. Margaret Edith</td>\n","      <td>female</td>\n","      <td>19.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>112053</td>\n","      <td>30.0000</td>\n","      <td>B42</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>889</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n","      <td>female</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>W./C. 6607</td>\n","      <td>23.4500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>890</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Behr, Mr. Karl Howell</td>\n","      <td>male</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>111369</td>\n","      <td>30.0000</td>\n","      <td>C148</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>891</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Dooley, Mr. Patrick</td>\n","      <td>male</td>\n","      <td>32.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>370376</td>\n","      <td>7.7500</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows Ã— 12 columns</p>\n","</div>"],"text/plain":["     PassengerId  Survived  Pclass  \\\n","0              1         0       3   \n","1              2         1       1   \n","2              3         1       3   \n","3              4         1       1   \n","4              5         0       3   \n","..           ...       ...     ...   \n","886          887         0       2   \n","887          888         1       1   \n","888          889         0       3   \n","889          890         1       1   \n","890          891         0       3   \n","\n","                                                  Name     Sex   Age  SibSp  \\\n","0                              Braund, Mr. Owen Harris    male  22.0      1   \n","1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                               Heikkinen, Miss. Laina  female  26.0      0   \n","3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                             Allen, Mr. William Henry    male  35.0      0   \n","..                                                 ...     ...   ...    ...   \n","886                              Montvila, Rev. Juozas    male  27.0      0   \n","887                       Graham, Miss. Margaret Edith  female  19.0      0   \n","888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n","889                              Behr, Mr. Karl Howell    male  26.0      0   \n","890                                Dooley, Mr. Patrick    male  32.0      0   \n","\n","     Parch            Ticket     Fare Cabin Embarked  \n","0        0         A/5 21171   7.2500   NaN        S  \n","1        0          PC 17599  71.2833   C85        C  \n","2        0  STON/O2. 3101282   7.9250   NaN        S  \n","3        0            113803  53.1000  C123        S  \n","4        0            373450   8.0500   NaN        S  \n","..     ...               ...      ...   ...      ...  \n","886      0            211536  13.0000   NaN        S  \n","887      0            112053  30.0000   B42        S  \n","888      2        W./C. 6607  23.4500   NaN        S  \n","889      0            111369  30.0000  C148        C  \n","890      0            370376   7.7500   NaN        Q  \n","\n","[891 rows x 12 columns]"]},"execution_count":357,"metadata":{},"output_type":"execute_result"}],"source":["train_df"]},{"cell_type":"code","execution_count":358,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T16:59:56.506179Z","iopub.status.busy":"2024-01-23T16:59:56.505906Z","iopub.status.idle":"2024-01-23T16:59:56.522605Z","shell.execute_reply":"2024-01-23T16:59:56.521594Z","shell.execute_reply.started":"2024-01-23T16:59:56.506155Z"},"trusted":true},"outputs":[],"source":["# Data Preprocessing\n","def preprocess_data(df):\n","    # Fill missing values\n","    df['Age'].fillna( df['Age'].mean(), inplace=True)\n","    df['Embarked'].fillna( df['Embarked'].mode()[0], inplace=True)\n","    df['Fare'].fillna( df['Fare'].mean(), inplace=True)\n","    \n","    \n","    df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n","    \n","    # Encode categorical features\n","    le = LabelEncoder()\n","    df['Sex'] = le.fit_transform(df['Sex'])\n","    df['Embarked'] = le.fit_transform(df['Embarked'])\n","    \n","    return df\n","\n","train_df = preprocess_data(train_df)\n","test_df = preprocess_data(test_df)\n","\n","# Split the data into features and labels\n","X = train_df.drop('Survived', axis=1).values\n","y = train_df['Survived'].values\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":359,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T16:59:56.524637Z","iopub.status.busy":"2024-01-23T16:59:56.524329Z","iopub.status.idle":"2024-01-23T16:59:56.539994Z","shell.execute_reply":"2024-01-23T16:59:56.539201Z","shell.execute_reply.started":"2024-01-23T16:59:56.524611Z"},"trusted":true},"outputs":[],"source":["# Preprocess the training data\n","#X_train, y_train = preprocess_data(train_data)\n","# Split the training data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","X_train\n"," # Convert data to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n","X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n","y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n"]},{"cell_type":"code","execution_count":360,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T16:59:56.541191Z","iopub.status.busy":"2024-01-23T16:59:56.540941Z","iopub.status.idle":"2024-01-23T16:59:56.551770Z","shell.execute_reply":"2024-01-23T16:59:56.550707Z","shell.execute_reply.started":"2024-01-23T16:59:56.541168Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([712, 8])"]},"execution_count":360,"metadata":{},"output_type":"execute_result"}],"source":["X_train_tensor.shape"]},{"cell_type":"code","execution_count":361,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T16:59:56.554173Z","iopub.status.busy":"2024-01-23T16:59:56.553800Z","iopub.status.idle":"2024-01-23T16:59:56.563873Z","shell.execute_reply":"2024-01-23T16:59:56.562920Z","shell.execute_reply.started":"2024-01-23T16:59:56.554139Z"},"trusted":true},"outputs":[],"source":["# Create DataLoader\n","train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n","batch_size = 64\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":362,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T16:59:56.565524Z","iopub.status.busy":"2024-01-23T16:59:56.565190Z","iopub.status.idle":"2024-01-23T16:59:56.578102Z","shell.execute_reply":"2024-01-23T16:59:56.577426Z","shell.execute_reply.started":"2024-01-23T16:59:56.565499Z"},"trusted":true},"outputs":[],"source":["# Define the Neural Network with Dropout\n","class TitanicMLP(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, dropout_rate):\n","        super(TitanicMLP, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.relu1 = nn.ReLU()\n","        self.dropout1 = nn.Dropout(p=dropout_rate)\n","        self.fc2 = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu1(x)\n","        x = self.dropout1(x)\n","        x = self.fc2(x)\n","        return x\n","# Instantiate the model\n","input_size = X_train.shape[1] #Number of features\n","hidden_size = 64\n","output_size = 2  # Binary classification (Survived or not)\n","dropout_rate = 0.5  # Adjust as needed\n","model = TitanicMLP(input_size, hidden_size, output_size, dropout_rate)\n"]},{"cell_type":"code","execution_count":363,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T16:59:56.599102Z","iopub.status.busy":"2024-01-23T16:59:56.598849Z","iopub.status.idle":"2024-01-23T16:59:56.603714Z","shell.execute_reply":"2024-01-23T16:59:56.602719Z","shell.execute_reply.started":"2024-01-23T16:59:56.599079Z"},"trusted":true},"outputs":[],"source":["# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":364,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T16:59:56.605509Z","iopub.status.busy":"2024-01-23T16:59:56.605200Z","iopub.status.idle":"2024-01-23T16:59:56.843729Z","shell.execute_reply":"2024-01-23T16:59:56.842785Z","shell.execute_reply.started":"2024-01-23T16:59:56.605475Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/10], Loss: 15.0918, Validation Loss: 6.5101, Accuracy: 57.54%\n","Epoch [2/10], Loss: 10.8215, Validation Loss: 3.2232, Accuracy: 59.22%\n","Epoch [3/10], Loss: 9.9793, Validation Loss: 1.9504, Accuracy: 60.34%\n","Epoch [4/10], Loss: 12.0388, Validation Loss: 1.2154, Accuracy: 62.01%\n","Epoch [5/10], Loss: 3.1293, Validation Loss: 2.3871, Accuracy: 62.01%\n","Epoch [6/10], Loss: 9.8914, Validation Loss: 1.7411, Accuracy: 62.01%\n","Epoch [7/10], Loss: 6.4962, Validation Loss: 1.9207, Accuracy: 62.57%\n","Epoch [8/10], Loss: 3.3613, Validation Loss: 0.7301, Accuracy: 71.51%\n","Epoch [9/10], Loss: 4.2709, Validation Loss: 1.8052, Accuracy: 63.13%\n","Epoch [10/10], Loss: 0.9076, Validation Loss: 0.6074, Accuracy: 70.39%\n"]}],"source":["# Training loop\n","epochs = 10\n","for epoch in range(epochs):\n","    model.train()\n","    for X_batch, y_batch in train_dataloader:\n","        optimizer.zero_grad()\n","        outputs = model(X_batch)\n","        loss = criterion(outputs, y_batch)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        \n","    # Validation\n","    model.eval()\n","    with torch.no_grad():\n","        val_loss = 0.0\n","        correct = 0\n","        total = 0\n","        for inputs, labels in val_dataloader:\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            val_loss += criterion(outputs, labels)\n","\n","        avg_val_loss = val_loss / len(val_dataloader)\n","        accuracy = correct / total * 100.0\n","\n","        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}, Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%')"]},{"cell_type":"code","execution_count":365,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T16:59:56.846240Z","iopub.status.busy":"2024-01-23T16:59:56.845874Z","iopub.status.idle":"2024-01-23T16:59:56.858761Z","shell.execute_reply":"2024-01-23T16:59:56.857926Z","shell.execute_reply.started":"2024-01-23T16:59:56.846204Z"},"trusted":true},"outputs":[],"source":["# Prediction on test set\n","X_test_tensor = torch.tensor(test_df.values, dtype=torch.float32)\n","test_dataset = TensorDataset(X_test_tensor)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","model.eval()\n","predictions = []\n","with torch.no_grad():\n","    for inputs in test_dataloader:\n","        outputs = model(inputs[0])\n","        _, predicted = torch.max(outputs, 1)\n","        predictions.extend(predicted.numpy())\n","\n","        print(\"Predicted Labels:\")\n","print(predicted_labels)"]},{"cell_type":"code","execution_count":366,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T16:59:56.860871Z","iopub.status.busy":"2024-01-23T16:59:56.860227Z","iopub.status.idle":"2024-01-23T16:59:56.873791Z","shell.execute_reply":"2024-01-23T16:59:56.873024Z","shell.execute_reply.started":"2024-01-23T16:59:56.860834Z"},"trusted":true},"outputs":[],"source":["# Save predictions to a CSV file\n","submission_df = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': predictions})\n","submission_df.to_csv('/kaggle/working/titanic_predictions.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":26502,"sourceId":3136,"sourceType":"competition"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
